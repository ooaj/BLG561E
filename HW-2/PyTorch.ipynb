{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wUsnQr4ryqK8"
   },
   "source": [
    "# Environment setup\n",
    "Follow the tutorial about how to utilize Google Colab but **don't install PyTorch** as mentioned in the blog post.\n",
    "\n",
    "Turkish:\n",
    "https://medium.com/deep-learning-turkiye/google-colab-ile-%C3%BCcretsiz-gpu-kullan%C4%B1m%C4%B1-30fdb7dd822e\n",
    "\n",
    "English:\n",
    "https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UL4h9pW8yqLA"
   },
   "source": [
    "\n",
    "# Now, you will work on the problem of Food Classification using a subset of Food-101 data, where you have 50 classes \n",
    "\n",
    "After having mounted the Jupyter Notebook to Google Drive, navigate the following address:\n",
    "\n",
    "https://drive.google.com/open?id=13zG2cXkDZiSGZTALgZD09OP7HSF1twWV\n",
    "\n",
    "Add this folder entirely to your Google Drive. If you have done it correctly, then you should be able to see blg561 in your drive.\n",
    "\n",
    "Let's try it with an simple example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qryg9cIOyqLE"
   },
   "source": [
    "### Don't forget to choose the right runtime from the menu above. (GPU should be selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5502,
     "status": "ok",
     "timestamp": 1542999656501,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "VOBaJnS2yqLM",
    "outputId": "a0a3e4f5-8357-40f7-8ca8-ec9f315b0fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 23 19:02:02 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# This command should return some information about the GPU status if the runtime is right. \n",
    "# In addition to that, if you encounter memory issues, you can diagnose your model by this command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656,
     "status": "ok",
     "timestamp": 1543244425723,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "qkXGwBlqnZeZ",
    "outputId": "f97c343a-1392-4360-a1c0-6ccb0a0970b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1543230624404,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "OKFaIIpy7Gu7",
    "outputId": "dc982c62-5a3d-4113-b036-429542ff5566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/BLG561E\n"
     ]
    }
   ],
   "source": [
    "# This is for navigating to the work folder. \n",
    "%cd /content/drive/My\\ Drive/BLG561E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49874,
     "status": "ok",
     "timestamp": 1543230676257,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "T3ear26kyqLV",
    "outputId": "d0f59eee-b948-4c01-a27d-3e87c78b0036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==0.4.1 (from -r blg561/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 519.5MB 31kB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x59a44000 @  0x7fac7f14d2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hCollecting torchvision==0.2.1 (from -r blg561/requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 20.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow==4.0.0 in /usr/local/lib/python3.6/dist-packages (from -r blg561/requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r blg561/requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r blg561/requirements.txt (line 5)) (1.14.6)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r blg561/requirements.txt (line 6)) (2.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1->-r blg561/requirements.txt (line 2)) (1.11.0)\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0->-r blg561/requirements.txt (line 3)) (0.46)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r blg561/requirements.txt (line 6)) (2.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r blg561/requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r blg561/requirements.txt (line 6)) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r blg561/requirements.txt (line 6)) (2.5.3)\n",
      "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-0.4.1 torchvision-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r blg561/requirements.txt\n",
    "# This code should install the required software if you did the integration correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "41iGvgE2yqLf"
   },
   "source": [
    "You are free to utilize Pytorch methods in this part of the Homework. \n",
    "You will be using pretained models VGG16, ResNet, Inception and your own model.\n",
    "\n",
    "Below, you will find required modules loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsIclTa7yqLg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import normalize, resize, to_tensor\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6792m6OyqLo"
   },
   "source": [
    "## DataLoader and Dataset\n",
    "Here, we provide you an almost fully functional Dataset but to ensure that you understood how it works, we request you to do a little adjustment. Try to understand how this loader code works and add Train/Test/Validation split to dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3ceScT0yqLr"
   },
   "outputs": [],
   "source": [
    "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
    "Image.register_extension = register_extension\n",
    "def register_extensions(id, extensions): \n",
    "    for extension in extensions: register_extension(id, extension)\n",
    "Image.register_extensions = register_extensions\n",
    "\n",
    "### The code below is to make you be able to load by using Pillow.\n",
    "class Food101Loader(Dataset):\n",
    "    def __init__(self, path, mode='train'):\n",
    "        self.images_path = os.path.join(path, './')\n",
    "        self.image_names = {}\n",
    "        for i,d in enumerate(os.listdir(self.images_path)):\n",
    "            try:\n",
    "                d = os.path.join(self.images_path, d)\n",
    "                single_class_path = {os.path.join(d,im):i for im in os.listdir(d)}\n",
    "                self.image_names= {**self.image_names, **single_class_path}\n",
    "            except:\n",
    "                print('err')\n",
    "        \n",
    "        self.image_names = [el for el in self.image_names.items()]\n",
    "        \n",
    "        def data_splitter(image_names, mode):\n",
    "          image_names = []\n",
    "          for i in range(0, 5000, 1000):\n",
    "            if mode == \"train\":\n",
    "              image_names.extend(self.image_names[i:i+600])\n",
    "            if mode == \"test\":\n",
    "              image_names.extend(self.image_names[i+600:i+800])\n",
    "            if mode == \"val\":\n",
    "              image_names.extend(self.image_names[i+800:i+1000])\n",
    "  \n",
    "          return image_names\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.image_names = data_splitter(self.image_names, mode)\n",
    "        if mode == 'test':\n",
    "            self.image_names = data_splitter(self.image_names, mode)\n",
    "        if mode == 'val':\n",
    "            self.image_names = data_splitter(self.image_names, mode)\n",
    "            \n",
    "    # This method normalizes each image individually. You may want to normalize it by using ImageNet statistics\n",
    "    # If you would like to fine tune so feel free to do changes\n",
    "    def preprocess(self, x):\n",
    "        x = resize(x, (224, 224))\n",
    "        x = np.asarray(x)\n",
    "        x = x.transpose((2,0,1))\n",
    "        x = torch.from_numpy(x).type(torch.float)\n",
    "        normalize(x,  mean=[el.mean() for el in x] ,std=[el.std() for el in x])\n",
    "        return x\n",
    "    \n",
    "    # This method basically loads image from the file system\n",
    "    def load(self, path):\n",
    "        img = Image.open(path)\n",
    "        img.load()\n",
    "        return img\n",
    "\n",
    "    # This method should be overrided in order to access the inside of dataset\n",
    "    def __getitem__(self, ix):\n",
    "        # Get its relative path and label\n",
    "        data_path, label = self.image_names[ix]\n",
    "        \n",
    "        # Load image\n",
    "        data = self.load(data_path)\n",
    "        data_normalized = self.preprocess(data)\n",
    "        data_normalized = data_normalized\n",
    "        \n",
    "        # Then return the data and its label.\n",
    "        return data_normalized, label\n",
    "        \n",
    "        \n",
    "    # This method should be overrided in order to make it work along with DataLoader class\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7js2q0T1yqLv"
   },
   "source": [
    "# Load separately VGG16, ResNet, Inception models\n",
    "\n",
    "You can find tutorials on how to load those models at pytorch.org . Don't forget to use pretrained=True if you wish to do finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wy7tKbstyqL0"
   },
   "outputs": [],
   "source": [
    "# Load models here\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "inception = models.inception_v3(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0-dMnwhyqL9"
   },
   "source": [
    "# Additionally, build your own model which is different from the other models, train on the Food dataset\n",
    "**Report your loss curves at the end of the notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oTm0xU8P1A6s"
   },
   "outputs": [],
   "source": [
    "class YourModel(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(100352, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "      \n",
    "model = YourModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kd9gLCzwBeej"
   },
   "outputs": [],
   "source": [
    "# v1\n",
    "class YourModelv1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourModelv1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(56 * 56 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = out.reshape(out.size(0), -1)\n",
    "      out = self.drop_out(out)\n",
    "      out = self.fc1(out)\n",
    "      out = self.fc2(out)\n",
    "      return out\n",
    "    \n",
    "model = YourModelv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myvBQ9zp7coy"
   },
   "outputs": [],
   "source": [
    "#v2\n",
    "class YourModelv2(nn.Module):\n",
    "  \"\"\"This is basically LeNet\"\"\"\n",
    "    def __init__(self):\n",
    "        super(YourModelv2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(44944, 32)\n",
    "        self.fc2   = nn.Linear(32, 32)\n",
    "        self.fc3   = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "      \n",
    "model = YourModelv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xwvxRkWQCIV7"
   },
   "outputs": [],
   "source": [
    "class YourModelv3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourModelv3, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(6272, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "      out = out.reshape(out.size(0), -1)\n",
    "      out = self.drop_out(out)\n",
    "      out = self.fc1(out)\n",
    "      out = self.fc2(out)\n",
    "      return out\n",
    "    \n",
    "model = YourModelv3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ppJHB-z4Crxw"
   },
   "outputs": [],
   "source": [
    "class YourModelv4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(YourModelv4, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(6272, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "    def forward(self, x):\n",
    "      out = self.layer1(x)\n",
    "      out = self.layer2(out)\n",
    "      out = self.layer3(out)\n",
    "      out = self.layer4(out)\n",
    "      out = out.reshape(out.size(0), -1)\n",
    "      out = self.drop_out(out)\n",
    "      out = self.fc1(out)\n",
    "      out = self.fc2(out)\n",
    "      return out\n",
    "    \n",
    "model = YourModelv4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2thf7JxyqMV"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset_train = Food101Loader(path='/content/drive/My Drive/BLG561E/blg561/data', mode='train')\n",
    "dataset_test = Food101Loader(path='/content/drive/My Drive/BLG561E/blg561/data', mode='test')\n",
    "dataset_val = Food101Loader(path='/content/drive/My Drive/BLG561E/blg561/data', mode='val')\n",
    "\n",
    "train_loader = DataLoader(dataset=dataset_train, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "test_loader = DataLoader(dataset=dataset_test, batch_size=32, num_workers=4, shuffle=False)\n",
    "val_loader = DataLoader(dataset=dataset_val, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5761,
     "status": "ok",
     "timestamp": 1543240237319,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "3N8yNYs5O7iP",
    "outputId": "0c7ffc28-1583-4cec-8679-e9c4d0c974c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YourModel(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (drop_out): Dropout(p=0.5)\n",
       "  (fc1): Linear(in_features=200704, out_features=1000, bias=True)\n",
       "  (fc2): Linear(in_features=1000, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(model.state_dict(), '/content/drive/My Drive/BLG561E/vgg16.ckpt')\n",
    "model = YourModel()\n",
    "model.load_state_dict(torch.load('/content/drive/My Drive/BLG561E/modelv1.ckpt'))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813180,
     "status": "ok",
     "timestamp": 1543258264484,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "O41jRbg72HQ2",
    "outputId": "fb224191-4676-49e0-e21b-3d59c56d4ef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number:  0\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.941240171809773  of  90 / 94 data\n",
      "Epoch Number:  1\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.9277623578121788  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.7674450938766066  of  90 / 94 data\n",
      "Epoch Number:  2\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.762175861489836  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.625551129968363  of  90 / 94 data\n",
      "Epoch Number:  3\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.6210570177425343  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.547241004798112  of  90 / 94 data\n",
      "Epoch Number:  4\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.5436022743306046  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.4865712134179518  of  90 / 94 data\n",
      "Epoch Number:  5\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.48442097606173  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.4467698641639342  of  90 / 94 data\n",
      "Epoch Number:  6\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.445751455821822  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.4121740439465937  of  90 / 94 data\n",
      "Epoch Number:  7\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.4111407452541345  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.381427340259221  of  90 / 94 data\n",
      "Epoch Number:  8\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.3799851969735397  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.3551302937567589  of  90 / 94 data\n",
      "Epoch Number:  9\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.354486596345057  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.326393751095555  of  90 / 94 data\n",
      "Epoch Number:  10\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.3255724322909883  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.301605829385504  of  90 / 94 data\n",
      "Epoch Number:  11\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.300177806414268  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.2773579080899558  of  90 / 94 data\n",
      "Epoch Number:  12\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.2759539333986327  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.2559567077224425  of  90 / 94 data\n",
      "Epoch Number:  13\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.2548856366294774  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.2351593444207563  of  90 / 94 data\n",
      "Epoch Number:  14\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.234527713300246  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.214884229348582  of  90 / 94 data\n",
      "Epoch Number:  15\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.2141488202491777  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.1947918839251337  of  90 / 94 data\n",
      "Epoch Number:  16\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.194477168468146  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.175481560723535  of  90 / 94 data\n",
      "Epoch Number:  17\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.174601819009763  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.1563918572194904  of  90 / 94 data\n",
      "Epoch Number:  18\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.1556655393503013  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.1387315285520077  of  90 / 94 data\n",
      "Epoch Number:  19\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.138199387479909  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.124197493796026  of  90 / 94 data\n",
      "Epoch Number:  20\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.1235946788868962  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.1076307315502234  of  90 / 94 data\n",
      "Epoch Number:  21\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.1072469451155844  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0916177783693586  of  90 / 94 data\n",
      "Epoch Number:  22\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.090842598155249  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0752062766763997  of  90 / 94 data\n",
      "Epoch Number:  23\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.0742780080808294  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0589130097397474  of  90 / 94 data\n",
      "Epoch Number:  24\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.0583890659200654  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0440165284444893  of  90 / 94 data\n",
      "Epoch Number:  25\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.0430958671348747  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0277809665028261  of  90 / 94 data\n",
      "Epoch Number:  26\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.02716499244021  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0136959252155273  of  90 / 94 data\n",
      "Epoch Number:  27\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.0131718277954689  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 1.0011810314841214  of  90 / 94 data\n",
      "Epoch Number:  28\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 1.000587369931138  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 0.9895739406949231  of  90 / 94 data\n",
      "Epoch Number:  29\n",
      "Iter Loss: 2.3088340759277344  of  0 / 94 data\n",
      "Mean Loss: 0.9889686593521546  of  0 / 94 data\n",
      "Iter Loss: 2.27192759513855  of  10 / 94 data\n",
      "Iter Loss: 1.993098258972168  of  20 / 94 data\n",
      "Iter Loss: 2.2352051734924316  of  30 / 94 data\n",
      "Iter Loss: 1.8209706544876099  of  40 / 94 data\n",
      "Iter Loss: 1.9229083061218262  of  50 / 94 data\n",
      "Iter Loss: 1.8635780811309814  of  60 / 94 data\n",
      "Iter Loss: 1.8241018056869507  of  70 / 94 data\n",
      "Iter Loss: 1.7456718683242798  of  80 / 94 data\n",
      "Iter Loss: 1.6708096265792847  of  90 / 94 data\n",
      "Mean Loss: 0.977927792694368  of  90 / 94 data\n",
      "30 EPOCHS COMPLETE. MODEL TRAINED.\n"
     ]
    }
   ],
   "source": [
    "###  Here are some training parameters\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "regularization_rate = 0\n",
    "n_epochs = 30\n",
    "use_gpu = False\n",
    "test_every = 3\n",
    "print_every  = 1\n",
    "steps = 0\n",
    "run_loss = 0\n",
    "###\n",
    "\n",
    "model = model\n",
    "# You may want to tweak them too.\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.99, weight_decay = 1e-5)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "# It modifies the behaviour of modules like BatchNorm and Dropout for training purposes\n",
    "model.cuda()\n",
    "criteria.cuda()\n",
    "\n",
    "model.train()\n",
    "\n",
    "# Some example diagnostics.\n",
    "\n",
    "# Loss for every iteration\n",
    "losses_iter_train = []\n",
    "\n",
    "# Loss for epoch (averaging the iteration-wise loss)\n",
    "losses_epoch_train = []\n",
    "accuracy_iter_train = []\n",
    "\n",
    "# Validation part\n",
    "losses_iter_val = []\n",
    "losses_epoch_val = []\n",
    "accuracy_iter_val = []\n",
    "\n",
    "# Write the training loop\n",
    "# https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#train-the-network\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch Number: ', epoch)\n",
    "    steps += 1\n",
    "\n",
    "    for ix, data in enumerate(train_loader):\n",
    "        \n",
    "        # Get the inputs\n",
    "        img, label = data    \n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model.forward(img)\n",
    "        loss = criteria(outputs, label)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate gradients for backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Train Loss\n",
    "        losses_iter_train.append(loss.item())\n",
    "        losses_epoch_train = np.mean(losses_iter_train)\n",
    "        \n",
    "        # Train Accuracy\n",
    "        ps = torch.exp(outputs).data\n",
    "        equality = (label.data == ps.max(1)[1])\n",
    "        accuracy_iter_train.append(equality.type_as(torch.FloatTensor()).mean())\n",
    "        if ix % 10 == 0:\n",
    "          print('Iter Loss:', losses_iter_train[ix], ' of ', ix, '/',len(train_loader), 'data')          \n",
    "        if ix % 90 == 0:\n",
    "          print('Mean Loss:', losses_epoch_train, ' of ', ix, '/',len(train_loader), 'data')\n",
    "\n",
    "\n",
    "    if steps % test_every == 0:\n",
    "\n",
    "      model.eval()\n",
    "\n",
    "      for img, label in iter(val_loader):\n",
    "        img, label = Variable(img), Variable(label)\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "          outputs = model.forward(img)\n",
    "          # Validation Loss\n",
    "          losses_iter_val.append(criteria(outputs, label).data.item())\n",
    "          losses_epoch_val = np.mean(losses_iter_val)\n",
    "          # Validation Accuracy\n",
    "          ps = torch.exp(outputs).data\n",
    "          equality = (label.data == ps.max(1)[1])\n",
    "          accuracy_iter_val.append(equality.type_as(torch.FloatTensor()).mean())\n",
    "        #print(\"Epoch: {}, Validation Loss: {}, Validation Accuracy: {}\".format(epoch, loss, val_acc))\n",
    "      '''print(\"Epoch: {}/{}.. \".format(epoch+1, n_epochs),\n",
    "       \"Training Loss: {:.3f}.. \".format(losses_epoch_train),\n",
    "        \"Val Loss: {:.3f}.. \".format(losses_epoch_val),\n",
    "        \"Val Accuracy: {:.3f}\".format(accuracy_iter_val[]))'''\n",
    "\n",
    "      model.train()\n",
    "            \n",
    "#Save_Path = '../Colab Notebooks'\n",
    "#Save_Name = 'resnet18.npz'\n",
    "#np.savez_compressed(os.path.join(Save_Path, Save_Name), val_losses = losses_epoch_val, val_accs = accuracy_iter_val, train_losses = accuracy_iter_train, train_accs = accuracy_iter_train)\n",
    "\n",
    "torch.save(model.state_dict(), '/content/drive/My Drive/BLG561E/modelv4.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3OrrfOdIGHIY"
   },
   "outputs": [],
   "source": [
    "#94#\n",
    "np.savez_compressed(\"/content/drive/My Drive/BLG561E/modelv4.npz\", val_losses = losses_epoch_val, val_accs = accuracy_iter_val, train_losses = losses_iter_train, train_accs = accuracy_iter_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-jfh_MAqyqMc"
   },
   "source": [
    "** Finetune/Train the loaded/designed model here:**\n",
    "\n",
    "Don't forget to include appropriate regularizations.\n",
    "Choose appropriate set of hyperparameters such as Learning Rate etc.\n",
    "\n",
    "You may insert new cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8E0LOfGdyqMj"
   },
   "source": [
    "### Measure the performance against validation set\n",
    "Complete the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12063,
     "status": "ok",
     "timestamp": 1543258512314,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "RAx2LRU1PqXx",
    "outputId": "4d1de31c-a7b3-4224-ae98-b42edfb015d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 54.8 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "   correct = 0\n",
    "   total = 0\n",
    "   for img, label in iter(test_loader):\n",
    "       img, label = Variable(img), Variable(label)\n",
    "       img = img.cuda()\n",
    "       label = label.cuda()\n",
    "       outputs = model(img)\n",
    "       _, predicted = torch.max(outputs.data, 1)\n",
    "       total += label.size(0)\n",
    "       correct += (predicted == label).sum().item()\n",
    "\n",
    "   print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMPvdNkTyqMw"
   },
   "source": [
    "** Run diagnostics for each model (VGG16, Resnet etc). Avoid overfitting and underfitting as much as possible.\n",
    "We expect you to get at least 75% Test Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWf94Qa4m2hZ"
   },
   "outputs": [],
   "source": [
    "# Load VGG16 from Drive\n",
    "vgg_16 = np.load(\"/content/drive/My Drive/BLG561E/vgg16_1.npz\")\n",
    "train_losses_vgg16 = vgg_16[\"train_losses\"]\n",
    "losses_epoch_vgg16 = vgg_16[\"val_losses\"]\n",
    "\n",
    "train_losses_mean_vgg16 = []\n",
    "for i in range(int(len(train_losses_vgg16)/94)):\n",
    "  train_losses_mean_vgg16.append(np.mean(train_losses_vgg16[i*94:(i+1)*94]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fqLc9Zg9yqMy"
   },
   "source": [
    "** Plot the training, validation, and test losses versus number of iterations or epochs for VGG16 on the same plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1543263688774,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "d_qBMaHVrALc",
    "outputId": "0d79dd07-4cb0-48ed-aaba-1b2b3a938708"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEVCAYAAAARjMm4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9hgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ff0487240>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16 Validation Losses [0.6205814981714208, 0.623522696976966, 0.5821454813505741, 0.5135625749826431, 0.5015165168554225, 0.45294412875429113]\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(len(train_losses_mean_vgg16)), train_losses_mean_vgg16, label='Train Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG16 Train Losses')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1543263785139,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "uDlDNozkr-a8",
    "outputId": "781cbcc4-9576-4e26-8518-49a994ca10ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for VGG16 is:  0.7964918832294643\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss for VGG16 is: \", losses_epoch_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtuiwY5ayqM8"
   },
   "source": [
    "** Plot the training, validation, and test losses versus number of iterations or epochs for ResNet on the same plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 674,
     "status": "ok",
     "timestamp": 1543263849158,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "7tmv2ebyyqM-",
    "outputId": "b3ab7af1-3230-4611-c0e7-b8026fdf8a80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "resnet_18 = np.load(\"/content/drive/My Drive/BLG561E/resnet18_1.npz\")\n",
    "train_losses_res18 = resnet_18[\"train_losses\"]\n",
    "losses_epoch_res18 = resnet_18[\"val_losses\"]\n",
    "\n",
    "train_losses_mean_res18 = []\n",
    "for i in range(int(len(train_losses_res18)/94)):\n",
    "  train_losses_mean_res18.append(np.mean(train_losses_vgg16[i*94:(i+1)*94]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1543263958971,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "XgfGn3nrsb_E",
    "outputId": "3c46f3c7-12f6-48e2-f4db-408a63f1dab3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEVCAYAAAARjMm4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTRO4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ff0936860>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(len(train_losses_mean_res18)), train_losses_mean_res18, label='Train Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Resnet18 Train Losses')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1543263909404,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "aCx80E-uskkT",
    "outputId": "70a1db47-d9e2-41a1-e7fa-f5da3d726a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for Resnest18 is:  0.7886888228356839\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss for Resnest18 is: \", losses_epoch_res18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wh6AM4tAyqNB"
   },
   "source": [
    "** Plot the training, validation, and test losses versus number of iterations or epochs for Inception on the same plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xHNdgxphyqNF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cXEwshTZyqNM"
   },
   "source": [
    "** Rather than using pretrained weights, first, initialize the weights by using small gaussian with zero mean and unit variance. Secondly, use the Xavier (Glorot) strategy to initialize the weights. Finally, discuss about the differences by comparing number of the epochs required to reach same testing accuracy, loss curves etc.**\n",
    "\n",
    "For more information about Xavier initialization, check out the following link:\n",
    "\n",
    "X. Glorot, Y. Bengio, 2010. Understanding the difficulty of training deep feedforward neural networks:  http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWE0o23GyqNP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDYFkotsyqNV"
   },
   "source": [
    "** Plot the training, validation, and test losses versus number of iterations or epochs for your model on the same plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 659,
     "status": "ok",
     "timestamp": 1543264126314,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "s4xrKwxzyqNW",
    "outputId": "61f900db-4258-4130-fd19-c36a70a867a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "mymodel = np.load(\"/content/drive/My Drive/BLG561E/modelv4.npz\")\n",
    "train_losses_mymodel = mymodel[\"train_losses\"]\n",
    "losses_epoch_mymodel = mymodel[\"val_losses\"]\n",
    "\n",
    "train_losses_mean_mymodel = []\n",
    "for i in range(int(len(train_losses_res18)/94)):\n",
    "  train_losses_mean_mymodel.append(np.mean(train_losses_mymodel[i*94:(i+1)*94]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1543264181935,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "soUO1HQ3tdPZ",
    "outputId": "f472a1a6-135b-43dc-c731-58219365f7a3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEVCAYAAAAGrllxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njPEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5ff095b4a8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(range(len(train_losses_mean_mymodel)), train_losses_mean_mymodel, label='Train Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Custom Model Train Losses')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 728,
     "status": "ok",
     "timestamp": 1543264202961,
     "user": {
      "displayName": "Ozgun A",
      "photoUrl": "",
      "userId": "01666726277915478621"
     },
     "user_tz": -180
    },
    "id": "K7CYoAtMtrGn",
    "outputId": "27a0d119-4c8e-424c-ed13-c62942f4d93a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss for custom model is:  1.2529722462873907\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss for custom model is: \", losses_epoch_mymodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zeCFMac7yqNd"
   },
   "source": [
    "#### After you have completed the training, save your best model using the following command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MB__uNcEyqNn"
   },
   "outputs": [],
   "source": [
    "student_id = 511161185\n",
    "torch.save(model.state_dict(), '/content/drive/My Drive/BLG561E/{}.pth'.format(student_id))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
